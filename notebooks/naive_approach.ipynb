{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.oauth2.credentials import Credentials\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from googleapiclient.discovery import build\n",
    "# from googleapiclient.http import MediaIoBaseDownload\n",
    "# import io\n",
    "# import os\n",
    "\n",
    "# # Authenticate\n",
    "# SCOPES = [\n",
    "#     'https://www.googleapis.com/auth/drive.metadata.readonly',  # View file metadata\n",
    "#     'https://www.googleapis.com/auth/drive.readonly'           # Download files\n",
    "# ]\n",
    "# flow = InstalledAppFlow.from_client_secrets_file('../credentials.json', SCOPES)\n",
    "# creds = flow.run_local_server(port=0)\n",
    "# service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# def download_folder(folder_id, destination):\n",
    "#     os.makedirs(destination, exist_ok=True)\n",
    "    \n",
    "#     # Get all files in folder\n",
    "#     results = service.files().list(\n",
    "#         q=f\"'{folder_id}' in parents\",\n",
    "#         pageSize=1000,\n",
    "#         fields=\"files(id, name)\"\n",
    "#     ).execute()\n",
    "    \n",
    "#     # Download each file\n",
    "#     for item in tqdm(results.get('files', [])):\n",
    "#         request = service.files().get_media(fileId=item['id'])\n",
    "#         fh = io.FileIO(os.path.join(destination, item['name']), 'wb')\n",
    "#         downloader = MediaIoBaseDownload(fh, request)\n",
    "        \n",
    "#         done = False\n",
    "#         while not done:\n",
    "#             status, done = downloader.next_chunk()\n",
    "#             print(f\"Download {item['name']} {int(status.progress() * 100)}%\")\n",
    "\n",
    "# # Usage\n",
    "# FOLDER_ID = \"17F6BKYkP_tr1nRJJw46TIa2jFVqxg5D6\"\n",
    "# # download_folder(FOLDER_ID, \"./data/raw/Flicker8k_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current working directory (where notebook is run)\n",
    "PROJECT_ROOT = Path().absolute()  # or Path.cwd()\n",
    "DATASET_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"Flicker8k_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/notebooks/data/raw/Flicker8k_Dataset')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/notebooks/data/raw/Flicker8k_Dataset')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2*8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# import zipfile\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Configuration\n",
    "# DATASET_URL = \"https://github.com/username/repo/raw/main/data/flickr8k.zip\"  # Hosted elsewhere\n",
    "# DATA_DIR = os.path.join(os.path.dirname(__file__), \"..\", \"data\")  # Project-relative path\n",
    "\n",
    "\n",
    "# def download_file(url, save_path):\n",
    "#     \"\"\"Download with progress bar\"\"\"\n",
    "#     os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "#     response = requests.get(url, stream=True)\n",
    "#     total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "#     with open(save_path, 'wb') as f, tqdm(\n",
    "#         desc=os.path.basename(save_path),\n",
    "#         total=total_size,\n",
    "#         unit='B',\n",
    "#         unit_scale=True\n",
    "#     ) as bar:\n",
    "#         for chunk in response.iter_content(chunk_size=1024):\n",
    "#             f.write(chunk)\n",
    "#             bar.update(len(chunk))\n",
    "\n",
    "# def setup_data():\n",
    "#     if not os.path.exists(os.path.join(RAW_DIR, \"Flicker8k_Dataset\")):\n",
    "#         print(\"Downloading dataset...\")\n",
    "#         zip_path = os.path.join(DATA_DIR, \"flickr8k.zip\")\n",
    "#         download_file(DATASET_URL, zip_path)\n",
    "        \n",
    "#         # Unzip\n",
    "#         with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(RAW_DIR)\n",
    "#         os.remove(zip_path)\n",
    "#         print(\"Dataset ready at:\", RAW_DIR)\n",
    "#     else:\n",
    "#         print(\"Dataset already exists\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     setup_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(67046) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting send2trash\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: send2trash\n",
      "Successfully installed send2trash-1.8.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install send2trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import send2trash  # \n",
    "\n",
    "# target_dir = '/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/raw/Flicker8k_Dataset'\n",
    "# protected = {'train', 'val', 'test'}\n",
    "\n",
    "# for item in os.listdir(target_dir):\n",
    "#     if item not in protected:\n",
    "#         try:\n",
    "#             send2trash.send2trash(os.path.join(target_dir, item))\n",
    "#             print(f\"Moved to trash: {item}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to move {item}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env from the project root (assuming notebook is in notebooks/)\n",
    "env_path = os.path.join(os.path.dirname(os.getcwd()), \".env\")  # Go up one level\n",
    "load_dotenv(env_path)\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Configuration\n",
    "DATASET_PATH = \"/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/raw/Flicker8k_Dataset\"\n",
    "OUTPUT_FILE = \"flickr8k_captions.csv\"\n",
    "BATCH_SIZE = 32  # Reduced batch size for better memory management\n",
    "NUM_CAPTIONS_PER_IMAGE = 3  # Reduced number of captions to save API costs\n",
    "SAVE_EVERY_N_BATCHES = 1\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")  # Get from environment variable\n",
    "\n",
    "class CaptionGenerator:\n",
    "    def __init__(self, dataset_path, output_file, batch_size=32, captions_per_image=3):\n",
    "        \"\"\"Initialize the caption generator with configuration parameters\"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.output_file = output_file\n",
    "        self.batch_size = batch_size\n",
    "        self.captions_per_image = captions_per_image\n",
    "        self.api_call_count = 0\n",
    "        self.total_cost_estimate = 0\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        \n",
    "        # Load CLIP model for scoring captions\n",
    "        print(\"Loading CLIP model...\")\n",
    "        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        \n",
    "        # Get image paths and check for previous results\n",
    "        self._prepare_image_paths()\n",
    "    \n",
    "    def _prepare_image_paths(self):\n",
    "        \"\"\"Get all image paths and filter out already processed ones\"\"\"\n",
    "        self.image_paths = glob.glob(os.path.join(self.dataset_path, \"*.jpg\"))\n",
    "        print(f\"Found {len(self.image_paths)} images in {self.dataset_path}\")\n",
    "        \n",
    "        # Check for previous results\n",
    "        self.results = []\n",
    "        self.processed_images = set()\n",
    "        \n",
    "        if os.path.exists(self.output_file):\n",
    "            previous_results = pd.read_csv(self.output_file)\n",
    "            self.results = previous_results.to_dict('records')\n",
    "            self.processed_images = set(previous_results['image'].values)\n",
    "            print(f\"Resuming from previous run. Already processed {len(self.processed_images)} images.\")\n",
    "        \n",
    "        # Filter out already processed images\n",
    "        self.image_paths = [path for path in self.image_paths \n",
    "                           if os.path.basename(path) not in self.processed_images]\n",
    "        print(f\"Remaining images to process: {len(self.image_paths)}\")\n",
    "    \n",
    "    def generate_captions(self, image_path):\n",
    "        \"\"\"Generate captions for a single image using GPT-3.5-Turbo\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that generates diverse image descriptions.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Generate {self.captions_per_image} simple descriptions for an image. Each description should be on a new line.\"}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            # Track API usage\n",
    "            self.api_call_count += 1\n",
    "            # Estimate cost: ~50 tokens input + ~120 tokens output per call\n",
    "            call_cost = (50 * 0.0005 / 1000) + (120 * 0.0015 / 1000)\n",
    "            self.total_cost_estimate += call_cost\n",
    "            \n",
    "            # Parse and clean captions\n",
    "            captions = response.choices[0].message.content.strip().split('\\n')\n",
    "            cleaned_captions = []\n",
    "            for caption in captions:\n",
    "                # Remove numbering patterns like \"1.\", \"1)\", \"[1]\", etc.\n",
    "                cleaned = caption.strip()\n",
    "                if cleaned and cleaned[0].isdigit() and len(cleaned) > 2 and cleaned[1:3] in ['. ', ') ', '- ', ': ']:\n",
    "                    cleaned = cleaned[3:].strip()\n",
    "                cleaned_captions.append(cleaned)\n",
    "            \n",
    "            return cleaned_captions\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating captions: {e}\")\n",
    "            # Return basic fallback captions\n",
    "            return [\"A photo of a scene\", \"An image\", \"A picture\"]\n",
    "    \n",
    "    def score_captions_with_clip(self, image, captions):\n",
    "        \"\"\"Score captions using CLIP model\"\"\"\n",
    "        inputs = self.clip_processor(text=captions, images=image, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.clip_model(**inputs)\n",
    "            probs = outputs.logits_per_image.softmax(dim=1)[0].detach().numpy()\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def process_batch(self, batch_paths, batch_idx, total_batches):\n",
    "        \"\"\"Process a batch of images\"\"\"\n",
    "        print(f\"\\nProcessing batch {batch_idx+1}/{total_batches} ({len(batch_paths)} images)\")\n",
    "        \n",
    "        batch_results = []\n",
    "        for img_path in tqdm(batch_paths):\n",
    "            try:\n",
    "                # Load image\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                \n",
    "                # Generate captions\n",
    "                candidate_captions = self.generate_captions(img_path)\n",
    "                \n",
    "                # Score captions with CLIP\n",
    "                scores = self.score_captions_with_clip(image, candidate_captions)\n",
    "                \n",
    "                # Select best caption\n",
    "                best_idx = np.argmax(scores)\n",
    "                best_caption = candidate_captions[best_idx]\n",
    "                best_score = float(scores[best_idx])\n",
    "                \n",
    "                # Store all captions and scores\n",
    "                all_captions_with_scores = [\n",
    "                    {'caption': caption, 'score': float(score)} \n",
    "                    for caption, score in zip(candidate_captions, scores)\n",
    "                ]\n",
    "                \n",
    "                # Add to results\n",
    "                result = {\n",
    "                    'image': os.path.basename(img_path),\n",
    "                    'best_caption': best_caption,\n",
    "                    'best_score': best_score,\n",
    "                    'all_captions': all_captions_with_scores\n",
    "                }\n",
    "                batch_results.append(result)\n",
    "                self.results.append(result)\n",
    "                \n",
    "                # Respect OpenAI rate limits\n",
    "                if self.api_call_count % 20 == 0:\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def save_progress(self):\n",
    "        \"\"\"Save current progress to files\"\"\"\n",
    "        # Save detailed results with all captions\n",
    "        detailed_df = pd.DataFrame(self.results)\n",
    "        detailed_df.to_json(self.output_file.replace('.csv', '_detailed.json'), orient='records')\n",
    "        \n",
    "        # Save simplified CSV with just image and best caption\n",
    "        simple_df = pd.DataFrame([\n",
    "            {'image': r['image'], 'caption': r['best_caption'], 'score': r['best_score']} \n",
    "            for r in self.results\n",
    "        ])\n",
    "        simple_df.to_csv(self.output_file, index=False)\n",
    "        \n",
    "        print(f\"Saved progress: {len(self.results)}/{len(self.image_paths) + len(self.processed_images)} images processed\")\n",
    "        print(f\"Estimated API cost so far: ${self.total_cost_estimate:.4f}\")\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the caption generation process\"\"\"\n",
    "        total_batches = (len(self.image_paths) + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for batch_idx in range(total_batches):\n",
    "            # Get batch paths\n",
    "            batch_start = batch_idx * self.batch_size\n",
    "            batch_end = min((batch_idx + 1) * self.batch_size, len(self.image_paths))\n",
    "            batch_paths = self.image_paths[batch_start:batch_end]\n",
    "            \n",
    "            # Process batch\n",
    "            self.process_batch(batch_paths, batch_idx, total_batches)\n",
    "            \n",
    "            # Save progress\n",
    "            if (batch_idx + 1) % SAVE_EVERY_N_BATCHES == 0 or batch_idx == total_batches - 1:\n",
    "                self.save_progress()\n",
    "        \n",
    "        print(f\"\\nCompleted captioning {len(self.results)} images\")\n",
    "        print(f\"Total estimated API cost: ${self.total_cost_estimate:.4f}\")\n",
    "        print(f\"Results saved to {self.output_file} and {self.output_file.replace('.csv', '_detailed.json')}\")\n",
    "\n",
    "\n",
    "# Run the caption generator\n",
    "# if __name__ == \"__main__\":\n",
    "#     generator = CaptionGenerator(\n",
    "#         dataset_path=DATASET_PATH,\n",
    "#         output_file=OUTPUT_FILE,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         captions_per_image=NUM_CAPTIONS_PER_IMAGE\n",
    "#     )\n",
    "#     generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CAPTIONS_PER_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP model...\n",
      "Found 809 images in /Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/raw/Flicker8k_Dataset/test\n",
      "Remaining images to process: 809\n",
      "\n",
      "Processing batch 1/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:14<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 16/809 images processed\n",
      "Estimated API cost so far: $0.0033\n",
      "\n",
      "Processing batch 2/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 32/809 images processed\n",
      "Estimated API cost so far: $0.0066\n",
      "\n",
      "Processing batch 3/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:22<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 48/809 images processed\n",
      "Estimated API cost so far: $0.0098\n",
      "\n",
      "Processing batch 4/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 64/809 images processed\n",
      "Estimated API cost so far: $0.0131\n",
      "\n",
      "Processing batch 5/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 80/809 images processed\n",
      "Estimated API cost so far: $0.0164\n",
      "\n",
      "Processing batch 6/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:16<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 96/809 images processed\n",
      "Estimated API cost so far: $0.0197\n",
      "\n",
      "Processing batch 7/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 112/809 images processed\n",
      "Estimated API cost so far: $0.0230\n",
      "\n",
      "Processing batch 8/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 128/809 images processed\n",
      "Estimated API cost so far: $0.0262\n",
      "\n",
      "Processing batch 9/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 144/809 images processed\n",
      "Estimated API cost so far: $0.0295\n",
      "\n",
      "Processing batch 10/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 160/809 images processed\n",
      "Estimated API cost so far: $0.0328\n",
      "\n",
      "Processing batch 11/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:14<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 176/809 images processed\n",
      "Estimated API cost so far: $0.0361\n",
      "\n",
      "Processing batch 12/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 192/809 images processed\n",
      "Estimated API cost so far: $0.0394\n",
      "\n",
      "Processing batch 13/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 208/809 images processed\n",
      "Estimated API cost so far: $0.0426\n",
      "\n",
      "Processing batch 14/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 224/809 images processed\n",
      "Estimated API cost so far: $0.0459\n",
      "\n",
      "Processing batch 15/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 240/809 images processed\n",
      "Estimated API cost so far: $0.0492\n",
      "\n",
      "Processing batch 16/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:14<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 256/809 images processed\n",
      "Estimated API cost so far: $0.0525\n",
      "\n",
      "Processing batch 17/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 272/809 images processed\n",
      "Estimated API cost so far: $0.0558\n",
      "\n",
      "Processing batch 18/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:16<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 288/809 images processed\n",
      "Estimated API cost so far: $0.0590\n",
      "\n",
      "Processing batch 19/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 304/809 images processed\n",
      "Estimated API cost so far: $0.0623\n",
      "\n",
      "Processing batch 20/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 320/809 images processed\n",
      "Estimated API cost so far: $0.0656\n",
      "\n",
      "Processing batch 21/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:16<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 336/809 images processed\n",
      "Estimated API cost so far: $0.0689\n",
      "\n",
      "Processing batch 22/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:21<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 352/809 images processed\n",
      "Estimated API cost so far: $0.0722\n",
      "\n",
      "Processing batch 23/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 368/809 images processed\n",
      "Estimated API cost so far: $0.0754\n",
      "\n",
      "Processing batch 24/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 384/809 images processed\n",
      "Estimated API cost so far: $0.0787\n",
      "\n",
      "Processing batch 25/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:15<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 400/809 images processed\n",
      "Estimated API cost so far: $0.0820\n",
      "\n",
      "Processing batch 26/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:16<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 416/809 images processed\n",
      "Estimated API cost so far: $0.0853\n",
      "\n",
      "Processing batch 27/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 432/809 images processed\n",
      "Estimated API cost so far: $0.0886\n",
      "\n",
      "Processing batch 28/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 448/809 images processed\n",
      "Estimated API cost so far: $0.0918\n",
      "\n",
      "Processing batch 29/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 464/809 images processed\n",
      "Estimated API cost so far: $0.0951\n",
      "\n",
      "Processing batch 30/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 480/809 images processed\n",
      "Estimated API cost so far: $0.0984\n",
      "\n",
      "Processing batch 31/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:15<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 496/809 images processed\n",
      "Estimated API cost so far: $0.1017\n",
      "\n",
      "Processing batch 32/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 512/809 images processed\n",
      "Estimated API cost so far: $0.1050\n",
      "\n",
      "Processing batch 33/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 528/809 images processed\n",
      "Estimated API cost so far: $0.1082\n",
      "\n",
      "Processing batch 34/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 544/809 images processed\n",
      "Estimated API cost so far: $0.1115\n",
      "\n",
      "Processing batch 35/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 560/809 images processed\n",
      "Estimated API cost so far: $0.1148\n",
      "\n",
      "Processing batch 36/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:15<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 576/809 images processed\n",
      "Estimated API cost so far: $0.1181\n",
      "\n",
      "Processing batch 37/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 592/809 images processed\n",
      "Estimated API cost so far: $0.1214\n",
      "\n",
      "Processing batch 38/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 608/809 images processed\n",
      "Estimated API cost so far: $0.1246\n",
      "\n",
      "Processing batch 39/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 624/809 images processed\n",
      "Estimated API cost so far: $0.1279\n",
      "\n",
      "Processing batch 40/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 640/809 images processed\n",
      "Estimated API cost so far: $0.1312\n",
      "\n",
      "Processing batch 41/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:14<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 656/809 images processed\n",
      "Estimated API cost so far: $0.1345\n",
      "\n",
      "Processing batch 42/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 672/809 images processed\n",
      "Estimated API cost so far: $0.1378\n",
      "\n",
      "Processing batch 43/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 688/809 images processed\n",
      "Estimated API cost so far: $0.1410\n",
      "\n",
      "Processing batch 44/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:17<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 704/809 images processed\n",
      "Estimated API cost so far: $0.1443\n",
      "\n",
      "Processing batch 45/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:19<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 720/809 images processed\n",
      "Estimated API cost so far: $0.1476\n",
      "\n",
      "Processing batch 46/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:15<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 736/809 images processed\n",
      "Estimated API cost so far: $0.1509\n",
      "\n",
      "Processing batch 47/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 752/809 images processed\n",
      "Estimated API cost so far: $0.1542\n",
      "\n",
      "Processing batch 48/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 768/809 images processed\n",
      "Estimated API cost so far: $0.1574\n",
      "\n",
      "Processing batch 49/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:18<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 784/809 images processed\n",
      "Estimated API cost so far: $0.1607\n",
      "\n",
      "Processing batch 50/51 (16 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:22<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 800/809 images processed\n",
      "Estimated API cost so far: $0.1640\n",
      "\n",
      "Processing batch 51/51 (9 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:08<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 809/809 images processed\n",
      "Estimated API cost so far: $0.1658\n",
      "\n",
      "Completed captioning 809 images\n",
      "Total estimated API cost: $0.1658\n",
      "Results saved to /Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/outputs/naive_test.csv and /Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/outputs/naive_test_detailed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator = CaptionGenerator(\n",
    "    dataset_path='/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/raw/Flicker8k_Dataset/test',\n",
    "    output_file='/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/outputs/naive_test.csv',\n",
    "    batch_size=16,\n",
    "    captions_per_image=NUM_CAPTIONS_PER_IMAGE\n",
    ")\n",
    "generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import random\n",
    "# import shutil\n",
    "# import pandas as pd\n",
    "\n",
    "# # Configuration\n",
    "# DATASET_PATH = \"/Users/ruhwang/Desktop/AI/spring2025_courses/aipi540-dl/caption_generator/data/raw/Flicker8k_Dataset/test\"\n",
    "# SAMPLE_SIZE = 300\n",
    "# SAMPLE_DIR = \"sampled_images\"\n",
    "# SAMPLE_FILE = \"sampled_images.csv\"\n",
    "\n",
    "# # Create sample directory if it doesn't exist\n",
    "# os.makedirs(SAMPLE_DIR, exist_ok=True)\n",
    "\n",
    "# # Get all image paths\n",
    "# image_paths = glob.glob(os.path.join(DATASET_PATH, \"*.jpg\"))\n",
    "# print(f\"Found {len(image_paths)} images in {DATASET_PATH}\")\n",
    "\n",
    "# # Randomly sample images\n",
    "# if len(image_paths) > SAMPLE_SIZE:\n",
    "#     sampled_paths = random.sample(image_paths, SAMPLE_SIZE)\n",
    "# else:\n",
    "#     sampled_paths = image_paths\n",
    "#     print(f\"Warning: Requested {SAMPLE_SIZE} samples but only found {len(image_paths)} images\")\n",
    "\n",
    "# # Copy sampled images to sample directory\n",
    "# sampled_data = []\n",
    "# for i, path in enumerate(sampled_paths):\n",
    "#     image_name = os.path.basename(path)\n",
    "#     dest_path = os.path.join(SAMPLE_DIR, image_name)\n",
    "#     shutil.copy(path, dest_path)\n",
    "#     sampled_data.append({\n",
    "#         'index': i,\n",
    "#         'image': image_name,\n",
    "#         'original_path': path\n",
    "#     })\n",
    "    \n",
    "# # Save sample information\n",
    "# sample_df = pd.DataFrame(sampled_data)\n",
    "# sample_df.to_csv(SAMPLE_FILE, index=False)\n",
    "\n",
    "# print(f\"Sampled {len(sampled_paths)} images and copied to {SAMPLE_DIR}\")\n",
    "# print(f\"Sample information saved to {SAMPLE_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
